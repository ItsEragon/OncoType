{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2758382,"sourceType":"datasetVersion","datasetId":1683013}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# If pytorch-grad-cam isn’t available via pip install,\n# you can install directly from GitHub:\n# !pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n# Or try the alias:\n!pip install grad-cam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:39:21.394516Z","iopub.execute_input":"2025-04-19T22:39:21.395035Z","iopub.status.idle":"2025-04-19T22:40:54.599747Z","shell.execute_reply.started":"2025-04-19T22:39:21.395009Z","shell.execute_reply":"2025-04-19T22:40:54.599086Z"}},"outputs":[{"name":"stdout","text":"Collecting grad-cam\n  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from grad-cam) (11.1.0)\nRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (2.5.1+cu124)\nRequirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.20.1+cu124)\nCollecting ttach (from grad-cam)\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.67.1)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.11.0.86)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from grad-cam) (3.7.5)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.1->grad-cam)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (3.6.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->grad-cam) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->grad-cam) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->grad-cam) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->grad-cam) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->grad-cam) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nBuilding wheels for collected packages: grad-cam\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=6d4a4c4fb3e2bc8a3825e9ca7c9b8c8193f3ede9c2aaf1b0fd6b97f556a0f4b7\n  Stored in directory: /root/.cache/pip/wheels/bc/52/78/893c3b94279ef238f43a9e89608af648de401b96415bebbd1f\nSuccessfully built grad-cam\nInstalling collected packages: ttach, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, grad-cam\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed grad-cam-1.5.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ttach-0.0.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, Dataset\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport numpy as np\nfrom pathlib import Path\n\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:40:54.601086Z","iopub.execute_input":"2025-04-19T22:40:54.601349Z","iopub.status.idle":"2025-04-19T22:41:05.527410Z","shell.execute_reply.started":"2025-04-19T22:40:54.601327Z","shell.execute_reply":"2025-04-19T22:41:05.526844Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Paths and parameters\nDATA_DIR = \"/kaggle/input/blood-cell-cancer-all-4class/Blood cell Cancer [ALL]\"\nBATCH_SIZE = 16\nNUM_CLASSES = 4\nNUM_EPOCHS = 10\nLR = 1e-4\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Class/severity mappings\nCLASS_NAMES = [\"Benign\", \"Early Pre-B\", \"Pre-B\", \"Pro-B\"]\nSEVERITY_MSG = {\n    0: \"A benign hematological entity exhibiting no signs of malignant transformation. The cellular morphology remains consistent with normal hematopoiesis, with preserved nuclear-to-cytoplasmic ratios, orderly chromatin, and the absence of atypical mitotic figures. No immediate clinical concern; routine surveillance may suffice.\",\n    1: \"An early-stage precursor B-cell malignancy, marked by subtle yet significant deviations from normal lymphopoiesis. These cells begin to demonstrate nuclear irregularities, increased nuclear-cytoplasmic ratio, and early chromatin dispersion — a harbinger of uncontrolled proliferation if left unchecked. Clinical intervention is crucial at this incipient stage.\",\n    2: \"A progressed pre-B lymphoblast population displaying clear morphological evidence of malignancy. Nuclear convolutions, prominent nucleoli, and cytoplasmic basophilia are characteristic. The disease at this stage possesses high proliferative potential, posing a significant systemic threat. Prompt and aggressive therapy is often indicated to curtail disease progression.\",\n    3: \"A highly aggressive and immature leukemic state, where pro-B lymphoblasts dominate. These cells exhibit profound anaplasia, scant cytoplasm, and dense chromatin irregularities. Rapid clinical deterioration is a hallmark; immediate, intensive therapeutic strategies are imperative for any hope of remission.\"\n}\n\n# Dataset\nclass BloodCancerDataset(Dataset):\n    def __init__(self, root, transform=None, filter_copy=True):\n        self.transform = transform\n        self.samples = []\n        root = Path(root)\n        for sub in root.iterdir():\n            if not sub.is_dir(): continue\n            name = sub.name\n            if 'Benign' in name: label = 0\n            elif 'Early Pre-B' in name or 'early Pre-B' in name: label = 1\n            elif 'Pro-B' in name and 'Pre-B' not in name: label = 3\n            elif 'Pre-B' in name: label = 2\n            else: continue\n            for img in sub.glob('*.jpg'):\n                if filter_copy and 'Copy' in img.name: continue\n                self.samples.append((str(img), label))\n        if not self.samples:\n            raise RuntimeError(f\"No images found under {root}\")\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        img = Image.open(path).convert('RGB')\n        if self.transform: img = self.transform(img)\n        return img, label\n\n# Transforms\ntfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\n# Load data\ndataset = BloodCancerDataset(DATA_DIR, transform=tfms)\nprint(f\"Total images: {len(dataset)}\")\ntrain_n = int(0.8*len(dataset))\nval_n = len(dataset) - train_n\ntrain_ds, val_ds = random_split(dataset, [train_n, val_n])\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:41:05.528416Z","iopub.execute_input":"2025-04-19T22:41:05.528776Z","iopub.status.idle":"2025-04-19T22:41:05.768447Z","shell.execute_reply.started":"2025-04-19T22:41:05.528752Z","shell.execute_reply":"2025-04-19T22:41:05.767708Z"}},"outputs":[{"name":"stdout","text":"Total images: 2847\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Build model function\ndef build_model():\n    m = models.resnet50(pretrained=True)\n    m.fc = nn.Linear(m.fc.in_features, NUM_CLASSES)\n    return m\n\n# Instantiate model and wrap for multi-GPU\nmodel = build_model().to(DEVICE)\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n\n# Loss & optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LR)\n\n# Training loop with per-class metrics\nbest_acc = 0.0\nsave_path = \"best_model.pth\"\nfor epoch in range(1, NUM_EPOCHS+1):\n    # --- Training ---\n    model.train()\n    running_loss = correct = total = 0\n    for x, y in train_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * x.size(0)\n        preds = out.argmax(1)\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n    tr_loss = running_loss / total\n    tr_acc = correct / total\n\n    # --- Validation ---\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for x, y in val_loader:\n            x, y = x.to(DEVICE), y.to(DEVICE)\n            out = model(x)\n            preds = out.argmax(1)\n            val_preds.extend(preds.cpu().tolist())\n            val_targets.extend(y.cpu().tolist())\n    val_acc = (np.array(val_preds) == np.array(val_targets)).mean()\n\n    # Report per-class metrics\n    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Train Loss {tr_loss:.4f} | \"\n          f\"Train Acc {tr_acc:.4f} | Val Acc {val_acc:.4f}\")\n    print(classification_report(val_targets, val_preds, target_names=CLASS_NAMES))\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(val_targets, val_preds))\n\n    # Save best\n    model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model_to_save.state_dict(), save_path)\n\n    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Loss {tr_loss:.4f} | \"\n          f\"Train Acc {tr_acc:.4f} | Val Acc {val_acc:.4f}\")\n\n# Load best model weights into a fresh architecture (no DataParallel)\nbest_model = build_model().to(DEVICE)\nbest_model.load_state_dict(torch.load(save_path, map_location=DEVICE))\nbest_model.eval()\n\n# Inference + Grad-CAM\ndef predict_and_explain(img_path):\n    img = Image.open(img_path).convert('RGB')\n    inp = tfms(img).unsqueeze(0).to(DEVICE)\n    out = best_model(inp)\n    cls = out.argmax(1).item()\n    print(f\"Predicted: {CLASS_NAMES[cls]}\")\n    print(SEVERITY_MSG[cls])\n    cam = GradCAM(model=best_model, target_layers=[best_model.layer4[-1]])\n    gcam = cam(input_tensor=inp, targets=[ClassifierOutputTarget(cls)])[0]\n    rgb = np.array(img.resize((224,224)), dtype=float) / 255\n    vis = show_cam_on_image(rgb, gcam, use_rgb=True)\n    Image.fromarray(vis).save(\"gradcam_out.jpg\")\n    print(\"Grad-CAM saved to gradcam_out.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:41:05.769899Z","iopub.execute_input":"2025-04-19T22:41:05.770131Z","iopub.status.idle":"2025-04-19T22:47:02.935709Z","shell.execute_reply.started":"2025-04-19T22:41:05.770114Z","shell.execute_reply":"2025-04-19T22:47:02.934886Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Using 2 GPUs\nEpoch 1/10 | Train Loss 0.2186 | Train Acc 0.9275 | Val Acc 0.9965\n              precision    recall  f1-score   support\n\n      Benign       1.00      0.98      0.99        99\n Early Pre-B       0.99      1.00      1.00       142\n       Pre-B       0.99      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      0.99      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 97   1   1   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 1/10 | Loss 0.2186 | Train Acc 0.9275 | Val Acc 0.9965\nEpoch 2/10 | Train Loss 0.0728 | Train Acc 0.9785 | Val Acc 0.9982\n              precision    recall  f1-score   support\n\n      Benign       1.00      0.99      0.99        99\n Early Pre-B       0.99      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 98   1   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 2/10 | Loss 0.0728 | Train Acc 0.9785 | Val Acc 0.9982\nEpoch 3/10 | Train Loss 0.0658 | Train Acc 0.9798 | Val Acc 1.0000\n              precision    recall  f1-score   support\n\n      Benign       1.00      1.00      1.00        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 3/10 | Loss 0.0658 | Train Acc 0.9798 | Val Acc 1.0000\nEpoch 4/10 | Train Loss 0.0393 | Train Acc 0.9881 | Val Acc 1.0000\n              precision    recall  f1-score   support\n\n      Benign       1.00      1.00      1.00        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 4/10 | Loss 0.0393 | Train Acc 0.9881 | Val Acc 1.0000\nEpoch 5/10 | Train Loss 0.0415 | Train Acc 0.9881 | Val Acc 1.0000\n              precision    recall  f1-score   support\n\n      Benign       1.00      1.00      1.00        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 5/10 | Loss 0.0415 | Train Acc 0.9881 | Val Acc 1.0000\nEpoch 6/10 | Train Loss 0.0402 | Train Acc 0.9899 | Val Acc 0.9965\n              precision    recall  f1-score   support\n\n      Benign       1.00      0.98      0.99        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       0.99      1.00      0.99       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      0.99      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 97   0   2   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 6/10 | Loss 0.0402 | Train Acc 0.9899 | Val Acc 0.9965\nEpoch 7/10 | Train Loss 0.0253 | Train Acc 0.9925 | Val Acc 0.9754\n              precision    recall  f1-score   support\n\n      Benign       0.90      1.00      0.95        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       0.98      0.97      0.98       163\n       Pro-B       1.00      0.95      0.97       166\n\n    accuracy                           0.98       570\n   macro avg       0.97      0.98      0.97       570\nweighted avg       0.98      0.98      0.98       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  5   0 158   0]\n [  6   0   3 157]]\nEpoch 7/10 | Loss 0.0253 | Train Acc 0.9925 | Val Acc 0.9754\nEpoch 8/10 | Train Loss 0.0253 | Train Acc 0.9925 | Val Acc 0.9930\n              precision    recall  f1-score   support\n\n      Benign       1.00      0.99      0.99        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       0.98      1.00      0.99       163\n       Pro-B       1.00      0.98      0.99       166\n\n    accuracy                           0.99       570\n   macro avg       0.99      0.99      0.99       570\nweighted avg       0.99      0.99      0.99       570\n\nConfusion Matrix:\n[[ 98   0   1   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   3 163]]\nEpoch 8/10 | Loss 0.0253 | Train Acc 0.9925 | Val Acc 0.9930\nEpoch 9/10 | Train Loss 0.0219 | Train Acc 0.9934 | Val Acc 1.0000\n              precision    recall  f1-score   support\n\n      Benign       1.00      1.00      1.00        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 9/10 | Loss 0.0219 | Train Acc 0.9934 | Val Acc 1.0000\nEpoch 10/10 | Train Loss 0.0181 | Train Acc 0.9965 | Val Acc 1.0000\n              precision    recall  f1-score   support\n\n      Benign       1.00      1.00      1.00        99\n Early Pre-B       1.00      1.00      1.00       142\n       Pre-B       1.00      1.00      1.00       163\n       Pro-B       1.00      1.00      1.00       166\n\n    accuracy                           1.00       570\n   macro avg       1.00      1.00      1.00       570\nweighted avg       1.00      1.00      1.00       570\n\nConfusion Matrix:\n[[ 99   0   0   0]\n [  0 142   0   0]\n [  0   0 163   0]\n [  0   0   0 166]]\nEpoch 10/10 | Loss 0.0181 | Train Acc 0.9965 | Val Acc 1.0000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_31/378333631.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  best_model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# Example:\npredict_and_explain(\"/kaggle/input/blood-cell-cancer-all-4class/Blood cell Cancer [ALL]/Benign/Sap_013 (10).jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:47:02.936549Z","iopub.execute_input":"2025-04-19T22:47:02.936795Z","iopub.status.idle":"2025-04-19T22:47:03.392786Z","shell.execute_reply.started":"2025-04-19T22:47:02.936772Z","shell.execute_reply":"2025-04-19T22:47:03.392164Z"}},"outputs":[{"name":"stdout","text":"Predicted: Benign\nA benign hematological entity exhibiting no signs of malignant transformation. The cellular morphology remains consistent with normal hematopoiesis, with preserved nuclear-to-cytoplasmic ratios, orderly chromatin, and the absence of atypical mitotic figures. No immediate clinical concern; routine surveillance may suffice.\nGrad-CAM saved to gradcam_out.jpg\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}